# 학습과정

+ 같은 문제라도 사람마다 푸는 방식이 다르고 학습된 결과다름 

+ 학습시킬 때 fit()함수를 사용 -> 그 인자에 따라 학습 결과가 차이가남

+ ex) 

  ```model.fit(x,y, batch_size=32, epochs=10)```

  + x:입력 데이터(예:문제)

  + y:라벨 값(예:답)

  + batch_size:몇 개의 샘플로 가중치를 갱신할 것인지  (예: 몇 문항을 풀고 해답을 맞추는 지를 의미)

    + 배치사이즈가 작을 수록 가중치 갱신이 자주 일어남
    +  배치사이즈가 크면 용량이 커야되고, 배치사이지가 작으면  학습은 꼼꼼이 잘 되지만시간이 너무 걸린다.

  + epochs:학습 반복 회수(예: 모의고사 1회분을 몇번 풀어볼까)

    + 같은 데이터셋을로 반보적으로 가중치를 갱신하면서 모델이 학습이 일어남

    + 반복해서 학습을 할 수록 학습하는 것이 줄어 든다.

    + 오버피팅: 너무 많이 학습하면 ,학습한 다른 것들을 까먹게 되는 현상

      ​		->오버피팅이 일어나는 지 체크하다가 조짐이 보이면 학습을 중단
